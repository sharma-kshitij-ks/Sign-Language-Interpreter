{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "american-sign-language.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfAVuJqnGLiK"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OfVgQVQ0GLo_"
      },
      "source": [
        "# Unzip the kaggle dataset and extract all the files. \n",
        "from zipfile import ZipFile \n",
        "file_name= '/content/drive/MyDrive/Dataset/sign-to-speech-dataset.zip'\n",
        "\n",
        "with ZipFile(file_name,'r') as zip:\n",
        "  zip.extractall()\n",
        "  print(\"Done\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hEkniJXmGLqw"
      },
      "source": [
        "#install the libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from IPython.display import Image\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Convolution2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.utils import np_utils\n",
        "\n",
        "import cv2\n",
        "import os\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5T2gt60Whauh"
      },
      "source": [
        "data_path='DATASET'\n",
        "categories=os.listdir(data_path)\n",
        "labels=[i for i in range(len(categories))]\n",
        "print(categories)\n",
        "print(labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0UfSx0OyFx1T"
      },
      "source": [
        "data_path='/content/DATASET/train'\n",
        "classes_path=os.listdir(data_path)\n",
        "print(classes_path)\n",
        "labels_classes=[i for i in range(len(classes_path))]\n",
        "print(labels_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPtBA3sMiXBJ"
      },
      "source": [
        "data_path='/content/DATASET/train'\n",
        "label_classes_dict = {}\n",
        "for directory in classes_path:\n",
        "  for value in labels_classes:\n",
        "    label_classes_dict[directory] = value\n",
        "    labels_classes.remove(value)\n",
        "    break\n",
        "label_classes_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13Q2I6hvFx1a"
      },
      "source": [
        "data_path='/content/DATASET/'\n",
        "img_size=128\n",
        "data=[]\n",
        "target=[]\n",
        "c=0\n",
        "minValue = 70\n",
        "for category in categories:\n",
        "    \n",
        "    cat_path=os.path.join(data_path,category)\n",
        "    print(cat_path)\n",
        "    cat_names=os.listdir(cat_path)\n",
        "    print(cat_names)\n",
        "    for classes in cat_names:\n",
        "        folder_path=os.path.join(data_path,category,classes)\n",
        "        print(folder_path)\n",
        "        img_names=os.listdir(folder_path)\n",
        "        #print(img_names)\n",
        "        for img_name in img_names:\n",
        "            #print(img_name)\n",
        "            img_path=os.path.join(folder_path,img_name)\n",
        "            img=cv2.imread(img_path)\n",
        "            \n",
        "            try:\n",
        "                gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY) \n",
        "                blur = cv2.GaussianBlur(gray,(5,5),2)\n",
        "                th3 = cv2.adaptiveThreshold(blur,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY_INV,11,2)\n",
        "                ret, res = cv2.threshold(th3, minValue, 255, cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n",
        "                #res=np.array(res)\n",
        "                #print(type(res))\n",
        "            #Converting the image into gray scale\n",
        "                resized=cv2.resize(res,(img_size,img_size))\n",
        "            #resizing the gray scale into 50x50, since we need a fixed common size for all the images in the dataset\n",
        "                data.append(resized)\n",
        "                #print(data)\n",
        "                target.append(label_classes_dict[classes])\n",
        "            except Exception as e:\n",
        "                print('Exception:',e)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5gRpKzpFx1c"
      },
      "source": [
        "data =np.array(data)\n",
        "target=np.array(target)\n",
        "(data.shape, target.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewpb5OTmFx1g"
      },
      "source": [
        "data=np.array(data)/255.0\n",
        "data=np.reshape(data,(data.shape[0],img_size,img_size,1))\n",
        "target=np.array(target)\n",
        "new_target=np_utils.to_categorical(target)\n",
        "\n",
        "np.save('data_img',data)\n",
        "np.save('target',new_target)\n",
        "\n",
        "data=np.load('data_img.npy')\n",
        "target=np.load('target.npy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qefXQlIyFx1k"
      },
      "source": [
        "train_data, test_data, train_target, test_target = train_test_split(data,new_target,\n",
        "                                                                    test_size=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4osMruOFx1l"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Convolution2D(32, (3, 3), input_shape=(128, 128, 1), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Convolution2D(32, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Convolution2D(32, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(units=128, activation='relu'))\n",
        "model.add(Dropout(0.40))\n",
        "model.add(Dense(units=96, activation='relu'))\n",
        "model.add(Dropout(0.40))\n",
        "model.add(Dense(units=64, activation='relu'))\n",
        "model.add(Dense(units=27, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy']) \n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LzLaQHRgoVdi"
      },
      "source": [
        "plot_model(model, to_file='convnet.png', show_shapes=True,show_layer_names=True)\n",
        "Image(filename='convnet.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aVI2SsVmFx1o"
      },
      "source": [
        "checkpoint = ModelCheckpoint('model-{epoch:03d}.model',\n",
        "                             monitor='val_loss',\n",
        "                             verbose=0,\n",
        "                             save_best_only=True,\n",
        "                             mode='auto')\n",
        "earlystopping = EarlyStopping(monitor = 'val_accuracy',\n",
        "                              min_delta = 0.01,\n",
        "                              patience = 5,\n",
        "                              mode = 'auto',\n",
        "                              restore_best_weights = True,\n",
        "                              verbose = 1)\n",
        "history = model.fit(train_data,\n",
        "                    train_target,\n",
        "                    shuffle=True,\n",
        "                    epochs=20,\n",
        "                    callbacks=[checkpoint, earlystopping],\n",
        "                    validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7FOF9AYFx1p"
      },
      "source": [
        "print('Validation Results')\n",
        "print(model.evaluate(test_data,test_target))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74aCbcP2WmpL"
      },
      "source": [
        "print(\"saving model...\")\n",
        "model.save('american-sign-language-detection-model.h5')\n",
        "print(\"Done!!!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVIdUQJtFx1r"
      },
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(['train_loss','val_loss'], loc=0)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hY1GLBG0Fx1r"
      },
      "source": [
        "\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(['train_accuracy','val_accuracy'], loc=0)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0SuVtJ-Fx1s"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}