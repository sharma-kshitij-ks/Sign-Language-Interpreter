{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "instant-time.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57LTPnUBcSdj",
        "outputId": "2f3d13c1-f269-4cfb-9876-c08974ae4935"
      },
      "source": [
        "!pip install gTTS \n",
        "  "
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gTTS\n",
            "  Downloading gTTS-2.2.3-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from gTTS) (7.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from gTTS) (2.23.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gTTS) (1.15.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->gTTS) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->gTTS) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->gTTS) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->gTTS) (2021.10.8)\n",
            "Installing collected packages: gTTS\n",
            "Successfully installed gTTS-2.2.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-MW6ab0bPNJ"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.models import load_model\n",
        "from keras.preprocessing.image import load_img, img_to_array\n",
        "\n",
        "import cv2\n",
        "from gtts import gTTS\n",
        "from playsound import playsound\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AoUjzeFhbPNW"
      },
      "source": [
        "model = keras.models.load_model(\"/content/american-sign-language-detection-model.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXmgW2S9bPNY"
      },
      "source": [
        "labels_dict = {0:'0', \n",
        "                 1:'A', \n",
        "                 2:'B', \n",
        "                 3:'C', \n",
        "                 4:'D', \n",
        "                 5:'E',\n",
        "                 6:'F',\n",
        "                 7:'G',\n",
        "                 8:'H',\n",
        "                 9:'I',\n",
        "                 10:'J',\n",
        "                 11:'K',\n",
        "                 12:'L',\n",
        "                 13:'M',\n",
        "                 14:'N',\n",
        "                 15:'O',\n",
        "                 16:'P',\n",
        "                 17:\"Q\",\n",
        "                 18:'R',\n",
        "                 19:'S',\n",
        "                 20:'T', \n",
        "                 21:'U', \n",
        "                 22:'V',\n",
        "                 23:'W',\n",
        "                 24:'X',\n",
        "                 25:'Y',\n",
        "                 26:'Z'}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dt9edNhvbPNb"
      },
      "source": [
        "# Completely Real-Time"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQ8xx9HCbPNe"
      },
      "source": [
        "color_dict=(0,255,0)\n",
        "x=0\n",
        "y=0\n",
        "w=64\n",
        "h=64\n",
        "img_size=128\n",
        "minValue = 70\n",
        "source=cv2.VideoCapture(0)\n",
        "count = 0\n",
        "string = \" \"\n",
        "prev = \" \"\n",
        "prev_val = 0\n",
        "while(True):\n",
        "    ret,img=source.read()\n",
        "    gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
        "    cv2.rectangle(img,(24,24),(250 , 250),color_dict,2)\n",
        "    crop_img=gray[24:250,24:250]\n",
        "    count = count + 1\n",
        "    if(count % 100 == 0):\n",
        "        prev_val = count\n",
        "    cv2.putText(img, str(prev_val//100), (300, 150),cv2.FONT_HERSHEY_SIMPLEX,1.5,(255,255,255),2) \n",
        "    blur = cv2.GaussianBlur(crop_img,(5,5),2)\n",
        "    th3 = cv2.adaptiveThreshold(blur,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY_INV,11,2)\n",
        "    ret, res = cv2.threshold(th3, minValue, 255, cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n",
        "    resized=cv2.resize(res,(img_size,img_size))\n",
        "    normalized=resized/255.0\n",
        "    reshaped=np.reshape(normalized,(1,img_size,img_size,1))\n",
        "    result = model.predict(reshaped)\n",
        "    #print(result)\n",
        "    label=np.argmax(result,axis=1)[0]\n",
        "    if(count == 300):\n",
        "        count = 99\n",
        "        prev= labels_dict[label] \n",
        "        if(label == 0):\n",
        "               string = string + \" \"             \n",
        "        else:\n",
        "                string = string + prev\n",
        "    cv2.putText(img, prev, (24, 14),cv2.FONT_HERSHEY_SIMPLEX,0.8,(255,255,255),2) \n",
        "    cv2.putText(img, string, (275, 50),cv2.FONT_HERSHEY_SIMPLEX,0.8,(200,200,200),2)\n",
        "    cv2.imshow(\"Gray\",res)    \n",
        "    cv2.imshow('LIVE',img)\n",
        "    key=cv2.waitKey(1)\n",
        "     \n",
        "    if(key==27):#press Esc. to exit\n",
        "        break\n",
        "print(string)        \n",
        "cv2.destroyAllWindows()\n",
        "source.release()\n",
        "\n",
        "cv2.destroyAllWindows()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_4jTXI1bPNh"
      },
      "source": [
        "\n",
        "# The text that you want to convert to audio \n",
        "\n",
        "language = 'en' #Language in which you want to convert \n",
        " \n",
        "myobj = gTTS(text=string, lang=language, slow=False) # Passing the text and language to the engine, here we have marked slow=False. Which tells the module that the converted audio should have a high speed\n",
        "myobj.save(\"welcome2121.mp3\") "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFrXpjjKc1FZ"
      },
      "source": [
        "  \n",
        "os.system(\"welcome.mp3\")  # Playing the converted file \n",
        "playsound('welcome2121.mp3')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sFd-u0KvbPNj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1eFHsPybPNk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}